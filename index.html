<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
  <title>CS 184 | Final Project</title>
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
  <link href="style.css" rel="stylesheet">

  <script>
    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
  </script>
  
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
  </script>
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
  <script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js">
  </script>
</head>

<body>

<header class="site-header" role="banner">
    <div class="wrapper">
        <a class="site-title" rel="author" href="/">CS 184 Final Project</a>
        <nav class="site-nav">
            <div class="trigger">
                <a class="page-link" target="_blank" href="/lens-flare-milestone/">Milestone</a>
                <a class="page-link" target="_blank" href="/cs184-proposal/">Proposal</a>
            </div>
        </nav>
    </div>  
</header>

<div align="middle" class="jumbo">
    <div class="content">
        <h2>Rendering Physically-Based Lens Flare Distortions</h2>

        <p>
            Noah Saso, Cassandra Melax, Aatif Jiwani, Ritwik Dixit
        </p>

        <p style="color: rgb(153, 209, 255); font-weight: bold; font-size: 18px;">Contents</p>

        <p style="color: rgb(153, 209, 255); font-size: 14px;">
            <a href="#abs">Abstract</a> | <a href="#sea">Starburst Effect Approach</a> | <a href="#ser">Starburst Effect Results</a>
        </p>
        <p style="color: rgb(153, 209, 255); font-size: 14px;">
            <a href="#gra">Ghost Reflections Approach</a> | <a href="#grr">Ghost Reflections Results</a> | <a href="#final">Final Results</a>
        </p>
        <p style="color: rgb(153, 209, 255); font-size: 14px;">
            <a href="#vid">Video</a> | <a href="#ref">References</a> | <a href="#cont">Contributions</a>
        </p>
    </div>
</div>
<div class="gradient"></div>

<div class="report">
    <a class="anchor" name="abs" style="text-decoration: none; "><h2>Abstract</h2></a>

    <p>
        Current methods for producing lens flare distortions are scene-independent, in the sense that they render a flare distortion without regard to the camera viewpoint or position of the sun, and synthetically overlay the distortion onto a scene that had been previously rendered or captured. In one case <b>[1]</b>, part of the lens flare was physically captured which may prove to be expensive and possibly time inefficient. For this project, we set out to develop a method such that we could render physics-based lens flare distortions that fully depend on the viewpoint and the location of the light source. 
    </p>

    <p>
        To be able to render a physics-based flare distortion, we dug deep into the science behind what causes them. To that end, we found that lens flares are composed of two pieces: a Starburst Effect and Ghost Reflections. As such, we divided our approach to focus on each component separately. 
    </p>

    <p>
        Our implementation is based off the Project 3-1 PathTracer. Our extended code can be viewed publicly at this <a href="https://github.com/aatifjiwani/lens-flare/" target="_blank">repository</a>. 
    </p>


    <a class="anchor" name="sea" style="text-decoration: none; "><h2>Starburst Effect - Approach</h2></a>

    <h3>Background</h3>

    <p>
        When nearby waves of light diffract through small apertures, the diffraction pattern that appears on an observation plane is usually modeled by the <a href="">Fresnel diffraction equation</a>. However, waves that originate especially from far-field light sources, like the sun, produce diffraction patterns that are modeled closely by the <a href="">Fraunhofer diffraction equation</a>: 
    </p>

    <div align="middle" style="margin-bottom: 10px;">

        <img src="media/fraunhofer.png">
        <img src="media/diffraction_plot.png">
        <br>
        <figcaption>Fraunhofer Diffraction</figcaption>
    </div>

    <p>
        The Fraunhaufer Diffraction Equation states that for a point $I = (x, y, z)$ on the observation plane, the complex magnitude of a diffracted wave with wavelength $\lambda$ is approximated by the complex integral over all points on the aperture plane $A$. Note that $k$ is the wavenumber, where $k = \frac{2\pi}{\lambda}$. 
        With knowledge of Fourier processing, the Fraunhofer diffraction equation can be equated to a <b>two-dimensional continuous-time Fourier transform</b>. However, since
        we intended on approximating the diffraction patterns of far-field light within a path tracing engine, performing a continuous 2D integral is intractable. Therefore, for our implementation, while we ray trace a pixel we simulateneously perform Monte Carlo integration over discrete samples of an aperture function $A(x', y')$ and render the diffraction pattern to the screen. 
    </p>

    <p>
        Before we further discuss the actual implementation, it is crucial to note how we adjust the lens flare based on the scene. The raw Fraunhofer diffraction equation, and thus the 2D Fourier transform, fails to account for the direction of the light waves as it hits the aperture plane. As a result, the lens flare would always situated at the origin of the rendered image. Based on properties of Fourier processing, we found that if we additionally modulate the aperture function $A(x', y')$ by $e^{j2\pi (x'u + y'v)}$ , where $(u,v)$ of offsets, then we can properly shift the lens flare based on where the sun is in the scene. This will be further discussed in the implementation.
    </p>

    <div align="middle" style="margin-bottom: 20px;">

        <img src="media/lensflare_centered.png">
        <img src="media/lensflare_adjusted.png">
        <br><br>
        <figcaption><b>Left:</b> Sample flare using the raw diffraction equation. <b>Right: </b>Same flare, but $A'(x', y') = A(x', y')e^{j2\pi (50x'-50y')}$</figcaption>
    </div>

    <h3>Path Tracer Implementation</h3>

    <p>
        We partition the starburst implementation in PathTracer into three sections. The first two sections focus on gathering data we need to perform the starburst computation. 
    </p>

    <div class="submodule">
        <img src="media/starburst_1.png" width="300px" style="float: left; margin-right: 20px;"/>
        <div class="subcontent" style="float: left; width: calc(100% - 350px);">
            <h3>1. Calculate the sun's position on the screen: </h3>
            <p>When the user inputs the COLLADA scene, we first check if there exists any directional lights. If there are, we perform the following for each and store their radiance: </p>
            <ul>
                <li>Given the directional light $D$ with direction $(u, v, w)$ in world-coordinates, we first convert the direction to camera-space: $D_C = R^T(D-T)$</li>
                <li>Calculate the sun's position on the image plane by extending the camera-space direction until it hits the $z = -1$ plane.</li>
                <li>Use the camera's $hFoV$ and $vFoV$ to calculate the <b>normalized screen-space</b> coordinates of the directional light.</li>
            </ul>
        </div>
    </div>

    <div class="submodule">
        <div class="subcontent" style="float: left; width: 80%">
            <h3>2. Load in the Aperture function as a texture: </h3>
            <p>As discussed above, the Starburst Effect inherently depends on the aperture function $A(x,y)$. However, to make this a tractable process, we can model the aperture function as a gray-scale image, where each pixel represents how much light will diffract if it hits that point on the aperture. Since the function is an image, we treat the aperture function $A(x,y)$ as a texture parameterized by coordinates $(u,v)$. To ensure we take only meaninful samples in the next section, we also calculate the bounding box of the non-zero region of the aperture function. </p>
        </div>
        <img src="media/pentf16.jpg" width="200px" style="float: left; margin-left: 20px;"/>
    </div>

    <div class="submodule">
        <img src="media/starburst_2.png" width="500px" style="float: left; margin-right: 20px;"/>
        <div class="subcontent" style="float: left; width: calc(100% - 550px);">
            <h3>3. Perform Monte Carlo integration for each screen pixel: </h3>
            <p>The ray-tracing procedure operates on a per-pixel basis, so to that end we compute the Starburst Effect per-pixel after the scene has been traced.
                We compute the starburst effect for each pixel $(x,y)$ as follows:
            </p>
            <ul>
                <li>Sample points $(u,v)$ on the aperture function.</li>
                <li>Complex modulate the sampled values by $e^{j2\pi(ux'+vy')}$ where $(x',y')$ are the screen-space offset of the lens flare. The offset is computed in Part 1.</li>
                <li>Perform Monte Carlo integration by taking the average of $A(u,v)e^{j2\pi(ux'+vy')}e^{-jk(ux + vy)}$ for all samples $(u,v)$</li>
                <li>The final result is the complex intensity of light that reaches pixel $(x,y)$. We take the real magnitude of the intensity, and scale it by the 
                    directional light's radiance to set the color of the pixel. 
                </li>
            </ul>
        </div>
    </div>

    <p>
        As a small implementation note, we added the ability to tune the size of the flare's inner radius and the overall intensity of the starburst. By tuning these parameters,
        we can effectively enhance the artistic nature of the lens flare. 
    </p>

    <a class="anchor" name="ser" style="text-decoration: none; "><h2>Starburst Effect - Results</h2></a>

    <h3>Background</h3>

    <p>
        A crucial step in producing photorealistic lens flares, after implementing the physically-based diffraction equation and other math described above, is to understand and design aperture functions that output desirable images. This involved deconstructing apertures into their smaller components and analyzing how individual attributes of the dirty models contributed to the rendered lens flares. Doing so allowed us to isolate three main features, each with their own variables:
    </p>
    <div class="center">
        <ul>
            <li>primary pupil's shape and size</li>
            <li>dots of varying size, position, and opacity</li>
            <li>lines of varying slope, length, position, and opacity</li>
        </ul>
    </div>

    <p>These components in tandem work to simulate a dirty lens and create an accurate depiction of a lens flare for a given scene.</p>

    <h3>Deconstruction</h3>

    <p>
        Below, the primary pupil is held constant while the effects of varying dots and lines are tested. We discovered that the presence and sizes of dots corresponded to radial artifacts that we see in the second from the left lens flare (on the bottom) which are not present in the plain one. These can lead to various subtle rings that appear toward the middle of lens flares. Additionally, lines corresponded to the 'rays' that appear to shoot out of the center of the starburst, with the slopes affecting the positions of these rays. Dots and lines as seen below simulate microscopic dust and scratches on the glass which significantly alter the diffraction of light.
    </p>

    <div class="center" style="margin-bottom:1rem">
        <div class="starburst-results">
            <img src="media/aperture_normal.png">
            <img src="media/aperture_normal.out.png">
        </div>
        <div class="starburst-results">
            <img src="media/aperture_dots.png">
            <img src="media/aperture_dots.out.png">
        </div>
        <div class="starburst-results">
            <img src="media/aperture_lines.png">
            <img src="media/aperture_lines.out.png">
        </div>
        <div class="starburst-results">
            <img src="media/aperture_both.png">
            <img src="media/aperture_both.out.png">
        </div>
    </div>

    <p>
        After settling on varying slopes of lines as the primary contributor to realistic looking lens flares in the above trials, we then experimented with varying pupil size and shape. A pentagon shaped pupil ended up creating interesting looking flares with stronger orbs in the center and subtle patterns in the diffracted light seen below. But most importantly, the size of the pupil contributed significantly to the character and emphasized components of the output flares. Smaller central pupils led to more intense and unique lens flares, while larger apertures led to fairly dim patterns that get washed out in scenes. The smallest sizes of pupils we tried ended up looking fairly unnatural; the sweet spot is probably somewhere between the second and third aperture functions below.
    </p>

    <div class="center" style="margin-bottom:1rem">
        <div class="starburst-results">
            <img src="media/pentf8.jpg">
            <img src="media/pentf8_starburst.jpg">
        </div>
        <div class="starburst-results">
            <img src="media/pentf16.jpg">
            <img src="media/pentf16_starburst.jpg">
        </div>
        <div class="starburst-results">
            <img src="media/pentf22.jpg">
            <img src="media/pentf22_starburst.jpg">
        </div>
        <div class="starburst-results">
            <img src="media/pentf32.jpg">
            <img src="media/pentf32_starburst.jpg">
        </div>
    </div>

    <p>
        The results seen above make sense since camera lenses tend to be quite small compared to the size of images they capture. The largest pupils don't produce very strong lens flares, probably because disturbances in the diffraction caused by the 'dirty' components are minimal compared to the amount of light taken in. When the pupil shrinks in relation to the scene and thus the image, the diffraction is more pronounced, and the artifacts we expect to see intensify.
    </p>

    <h3>Results</h3>

    <p>
        Putting it all together, here are some scenes rendered with various aperture functions. On the left is the Blender scene with a directional light source.
    </p>

    <h4>Dragon</h4>
    <div class="center starburst-renders">
        <img src="media/dragon_blender.png" height="200" style="margin-bottom: 1rem;">
        <div class="starburst-results bigger">
            <img src="media/bbg_psmll.png">
            <img src="media/dragon_psmll.png">
        </div>
        <div class="starburst-results bigger">
            <img src="media/bbg_p4_15.png">
            <img src="media/dragon_p4_15.png">
        </div>
        <div class="starburst-results bigger">
            <img src="media/bbg_p500_14.png">
            <img src="media/dragon_p500_14.png">
        </div>
    </div>

    <p>
        The starburst on the far left is rendered with the smallest aperture function and more lines with similar slopes, leading to the wider gaps between the groups of rays seen in the flare. The middle starburst is created with a slightly larger pupil and a more even distribution of slopes of lines. The last flare is rendered with the largest pupil, leading to the faint pattern which is hard to differentiate from a typical point light source.
    </p>

    <h4>Pyramids</h4>
    <div class="center starburst-renders">
        <img src="media/pyramid_blender.png" height="200" style="margin-bottom: 1rem;">
        <div class="starburst-results bigger">
            <img src="media/bbg_psmll.png">
            <img src="media/pyramid_pentsmll.png">
        </div>
        <div class="starburst-results bigger">
            <img src="media/bbg_p500_14.png">
            <img src="media/pyramid_p500_14.png">
        </div>
    </div>

    <p>
        In the above scenes, we only render the pyramids with the extremes: an aperture function with a small pupil (on the left) and a large pupil (on the right). The difference is much more apparent than in the dragon scene due to the scenes' different environments. Needless to say, the aperture function used on the left is impressively photorealistic compared to the others.
    </p>

    <a class="anchor" name="gra" style="text-decoration: none; "><h2>Ghost Reflections - Approach</h2></a>


    <a class="anchor" name="grr" style="text-decoration: none; "><h2>Ghost Reflections - Results</h2></a>


    <a class="anchor" name="final" style="text-decoration: none;"><h2>Final Results</h2></a>

    <h3>Renders</h3>

    <p>Some Content</p>

    <div class="submodule">
        <img src="media/pyramid_pentsmll_ghost.gif" width="31.5%" style="float: left; padding-left: 10px; padding-right: 10px;"/>
        <img src="media/pyramid_pent4_17_ghost.png" width="31.5%" style="float: left; padding-left: 10px; padding-right: 10px;"/>
        <img src="media/custom_ghost.png" width="31.5%" style="float: left; padding-left: 10px; padding-right: 10px;"/>
    </div>

    <h3>Final Animation</h3>

    <p>Some Content</p>

    <video width="400" controls style="margin: 0 auto; width: 400px;">
        <source src="media/animation.mp4" type="video/mp4">
        Your browser does not support HTML video.
    </video>


    <a class="anchor" name="vid" style="text-decoration: none;"><h2>Video</h2></a>


    <a class="anchor" name="ref" style="text-decoration: none;"><h2>References</h2></a>

    <p>
        <strong>[1]: </strong> Wu, Yicheng et al. 2020. Single-Image Lens Flare Removal. ArXiv abs/2011.12485: n. pag.
    </p>

    <p>
        <strong>[2]: </strong>Matthias Hullin, Elmar Eisemann, Hans-Peter Seidel, and Sungkil Lee. 2011. Physically-based real-time lens flare rendering. <br>ACM Trans. Graph. 30, 4, Article 108 (July 2011), 10 pages. DOI:https://doi.org/10.1145/2010324.1965003
    </p>

    <p>
        <strong>[3]: </strong>Sangmin Lee and Sungkil Lee. 2016. Interactive additive diffraction synthesis.<br>In Proceedings of the 37th Annual Conference of the European Association for Computer Graphics: Posters (EG '16). Eurographics Association, Goslar, DEU, 11â€“12.
    </p>



    <a class="anchor" name="cont" style="text-decoration: none;"><h2>Contributions</h2></a>


</div>
</body>
</html>